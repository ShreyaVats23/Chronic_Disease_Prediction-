# -*- coding: utf-8 -*-
"""Tuned_Logistic_Regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QG7Acb2Mz8f1OrGR7Q6yY3vB4buiJVnA
"""

from google.colab import drive
drive.mount('/content/drive')

"""# **Step 1:** AIM - Finding Chronic Disease"""

#importing the necessary modules and packages
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

"""# **Step 2:** Data Loading"""

#LOADING THE DATA
df=pd.read_csv(r'/content/drive/MyDrive/health_lifestyle.csv')
df

"""# **Step 3:** Data Information Gathering"""

#finding the number of rows and columns
df.shape

# display the information related to dataset
df.info()

#to generate descriptive statistics
df.describe()

#display the first n number of rows
df.head(10)

#display the n number of rows from bottom
df.tail(10)

#counts the number of non-null values in each column (by default)
df.count()

#count the total number of duplicate rows
df.duplicated().sum()

# count the number of missing (NaN) values in each column
df.isnull().sum()

"""# **Step 4:** Data Cleaning"""

#filling missing values
df["Exercise_Freq"]=df["Exercise_Freq"].fillna(df["Exercise_Freq"].mode()[0])
df["Alcohol_Consumption"]=df["Alcohol_Consumption"].fillna(df["Alcohol_Consumption"].mode()[0])

df.isnull().sum()

#dropping columns which are not required
df.drop(['ID'], axis=1, inplace=True)
df

"""# **Step 5:** Data Visualization"""

#Pie chart representing alcohol consumption distribution

df['Alcohol_Consumption'].value_counts().plot.pie(autopct='%1.1f%%')
plt.title('Alcohol Consumption Distribution')
plt.ylabel('')
plt.show()

# bar plot of age each of different color
from matplotlib import cm
n, bins, patches = plt.hist(df['Age'], bins=6)

# Generate different shades of blue using colormap
colors = cm.Blues(np.linspace(0.4, 0.9, len(patches)))

# Apply shades to each bar
for patch, color in zip(patches, colors):
    patch.set_facecolor(color)

# Labels and title
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Age Distribution')
plt.show()

#Helps understand how many people have chronic disease — useful for health prediction.
sns.countplot(x='Chronic_Disease', data=df)
plt.title('Chronic Disease Count (0 = No, 1 = Yes)')
plt.show()

#checking relationship between BMI and health condition
#Shows BMI distribution for healthy vs diseased
sns.boxplot(x='Chronic_Disease', y='BMI', data=df)
plt.title('BMI vs Chronic Disease')
plt.show()

#Proves if smoking is a risk factor
sns.countplot(x='Smoker', hue='Chronic_Disease', data=df)
plt.title('Smoker vs Chronic Disease')
plt.show()

#Shows skewness or outliers in sleep data
df['Sleep_Hours'].hist(bins=20)
plt.title("Distribution of Sleep Hours")
plt.xlabel("Hours")
plt.ylabel("Frequency")
plt.show()

#helps understand if age might influence BMI in your target group.
sns.scatterplot(x='Age', y='BMI',hue='Chronic_Disease', data=df)
plt.title('Age vs BMI')
plt.show()

#correlation between age and target variable
# shows whether older individuals tend to have chronic disease
sns.boxplot(x='Chronic_Disease', y='Age', data=df)
plt.title('Age vs Chronic Disease')
plt.show()

#calculate percentage of outliers using IQR
numeric_cols = ['BMI', 'Age', 'Height_cm', 'Weight_kg', 'Sleep_Hours']

# Calculate Q1, Q3, and IQR
Q1 = df[numeric_cols].quantile(0.25)
Q3 = df[numeric_cols].quantile(0.75)
IQR = Q3 - Q1

# Calculate outliers using IQR rule
outlier_condition = ((df[numeric_cols] < (Q1 - 1.5 * IQR)) |
                     (df[numeric_cols] > (Q3 + 1.5 * IQR)))

# Count outliers per column
outlier_counts = outlier_condition.sum()

# Total rows in dataset
total_rows = len(df)

# Calculate % of outliers
outlier_percent = (outlier_counts / total_rows) * 100

# Show results
print("Outliers per column (%):\n")
print(outlier_percent)

#inspect unique values before mapping.
print(df['Smoker'].unique())
print(df['Diet_Quality'].unique())
print(df['Alcohol_Consumption'].unique())
print(df['Exercise_Freq'].unique())
print(df['Chronic_Disease'].unique())

"""<!-- **Note:** In the following table, the 'Actual' and 'Prediction' values for 'Stress_Level' correspond to the following categories:


1 = High stress (original stress 7–10)

0 = Not High stress (1–6) -->
"""

#mapping
df['Smoker'] = df['Smoker'].map({'No': 0, 'Yes': 1})

df['Gender'] = df['Gender'].map({'Female': 0, 'Male': 1,'Other':2})

df['Diet_Quality'] = df['Diet_Quality'].map({'Poor': 0, 'Average': 1, 'Good': 2, 'Excellent': 3})

df['Alcohol_Consumption'] = df['Alcohol_Consumption'].map({'Low': 0, 'Moderate': 1, 'High': 2})

df['Exercise_Freq'] = df['Exercise_Freq'].map({'1-2 times/week': 0, '3-5 times/week': 1, 'Daily': 2})

df['Chronic_Disease'] = df['Chronic_Disease'].map({'No': 0, 'Yes': 1})



# # #divide stress level into 3 categories from scale 1-10
# # df['Stress_Level'] = pd.cut(df['Stress_Level'], bins=[0, 3, 6, 10], labels=['Low', 'Medium', 'High'])
# # df['Stress_Level'] = df['Stress_Level'].map({'Low': 0, 'Medium': 1, 'High': 2})

# # Binary: 1 = High stress (original stress 7–10), 0 = Not High stress (1–6)
# df['Stress_Level'] = df['Stress_Level'].apply(lambda x: 1 if x >= 7 else 0)

#checking mapping result on dataset
df.head()

df.dtypes

"""# **PERFORMING SCALING**"""

#performing scaling
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[['BMI','Age','Height_cm','Weight_kg','Sleep_Hours','Stress_Level']] = scaler.fit_transform(df[['BMI','Age','Height_cm','Weight_kg','Sleep_Hours','Stress_Level']])
df

"""# **HEATMAP**"""

cor=df.corr()
plt.figure(figsize=(12,8))
sns.heatmap(data=cor,annot=True,fmt=".2f")
plt.title("Correlation Heatmap",size=13)
plt.show()

# plt.figure(figsize=(10, 8))
# sns.heatmap(df.corr(), annot=True, cmap='coolwarm', linewidths=0.5)
# plt.title("Correlation Heatmap")
# plt.show()

"""# **DIVIDING X AND Y(INPUTS AND TARGET)**"""

# dividing into x(input column)
X = df.drop(columns=["Chronic_Disease"])
# Y(target column)
Y = df['Chronic_Disease']


X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

X

Y

#binary classification

#take sample input and converting them into scaled inputs
#Age	Gender	Height_cm	Weight_kg	BMI	Smoker	Exercise_Freq	Diet_Quality	Alcohol_Consumption	Stress_Level	Sleep_Hours

# This must match the actual feature columns used during training
columns_order = ['Age', 'Gender', 'Height_cm', 'Weight_kg', 'BMI',
                 'Smoker', 'Exercise_Freq', 'Diet_Quality',
                 'Alcohol_Consumption', 'Stress_Level', 'Sleep_Hours']

# The 6 numeric columns scaled during training
scaled_cols = ['BMI', 'Age', 'Height_cm', 'Weight_kg', 'Sleep_Hours', 'Stress_Level']

#scaled sample input 1-------
sample_input = np.array([[56, 2, 177.6, 37.3, 11.8, 1, 2, 0, 0, 9, 8.5]])   #actual no-0

# Convert to DataFrame
sample_df1 = pd.DataFrame(sample_input, columns=columns_order)

# Apply scaling only to required columns
sample_df1[scaled_cols] = scaler.transform(sample_df1[scaled_cols])

sample_df1

#scaled sample input 2------#actual yes-1
sample_input2 = np.array([[60, 1, 158.4, 60.4, 24.1, 0, 1, 3, 0, 6, 6.1]])

sample_df2 = pd.DataFrame(sample_input2, columns=columns_order)
sample_df2[scaled_cols] = scaler.transform(sample_df2[scaled_cols])

sample_df2

#scaled sample input 3-----#actual no-0
sample_input3 = np.array([[32, 1, 170.6, 76.4, 26.3, 0, 1, 3, 1, 9, 6.6]])

sample_df3 = pd.DataFrame(sample_input3, columns=columns_order)
sample_df3[scaled_cols] = scaler.transform(sample_df3[scaled_cols])

sample_df3

#LOGISTIC REGRESSION
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Define parameter grid
param_grid = {
    'C': [0.01, 0.1, 1, 10],              # Regularization strength
    'penalty': ['l1', 'l2'],              # Type of regularization
    'solver': ['liblinear']               # Supports both L1 and L2
}

# Step 2: Base model with class weights
model1 = LogisticRegression(class_weight='balanced', random_state=42)

# Step 3: Grid search with 5-fold cross-validation
grid_search = GridSearchCV(estimator=model1,param_grid=param_grid, scoring='f1',
                           cv=5,n_jobs=-1)

# Step 4: Fit on training data
grid_search.fit(X_train, Y_train)

# Step 5: Best model
best_log_model = grid_search.best_estimator_
print("Best Parameters:", grid_search.best_params_)

# Step 6: Predict on test data
y_pred = best_log_model.predict(X_test)

# Step 7: Evaluation
score1= accuracy_score(Y_test, y_pred)
print(" Accuracy:", score1)
print(" Confusion Matrix:\n", confusion_matrix(Y_test, y_pred))
print(" Classification Report:\n", classification_report(Y_test, y_pred))

# Step 8: Predict on sample inputs
pred1 = best_log_model.predict(sample_df1)[0]
pred1_2 = best_log_model.predict(sample_df2)[0]
pred1_3 = best_log_model.predict(sample_df3)[0]

print("\n Sample Input Predictions:")
print("Sample 1:", "Chronic Disease" if pred1 == 1 else "No Disease")
print("Sample 2:", "Chronic Disease" if pred1_2 == 1 else "No Disease")
print("Sample 3:", "Chronic Disease" if pred1_3 == 1 else "No Disease")

#DECISION TREE
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Define parameter grid
param_grid_dt = {
    'max_depth': [3, 5, 10, 15, None],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'criterion': ['gini', 'entropy'],
    'class_weight': ['balanced']  # helps handle imbalance
}

# Step 2: Create base Decision Tree model
model2 = DecisionTreeClassifier(random_state=42)

# Step 3: Grid Search with F1 scoring
grid_search_dt = GridSearchCV(estimator=model2, param_grid=param_grid_dt,
                              scoring='f1', cv=5, n_jobs=-1)

# Step 4: Fit the model
grid_search_dt.fit(X_train, Y_train)

# Step 5: Get best model
best_dt = grid_search_dt.best_estimator_
print("Best Parameters:", grid_search_dt.best_params_)

# Step 6: Predict
y_pred_dt = best_dt.predict(X_test)

# Step 7: Evaluate
score2 = accuracy_score(Y_test, y_pred_dt)
print(" Accuracy:", score2 )
print(" Confusion Matrix:\n", confusion_matrix(Y_test, y_pred_dt))
print("Classification Report:\n", classification_report(Y_test, y_pred_dt))

# Step 8: Predict on your sample inputs
pred2 = best_dt.predict(sample_df1)[0]
pred2_2 = best_dt.predict(sample_df2)[0]
pred2_3 = best_dt.predict(sample_df3)[0]

print("\n Sample Input Predictions:")
print("Sample 1:", "Chronic Disease" if pred2 == 1 else "No Disease")
print("Sample 2:", "Chronic Disease" if pred2_2 == 1 else "No Disease")
print("Sample 3:", "Chronic Disease" if pred2_3 == 1 else "No Disease")

#binary decision tree
from sklearn.tree import plot_tree

plt.figure(figsize=(20, 10))  # You can increase size if needed
plot_tree(best_dt,
          feature_names=X.columns,
          class_names=["No Disease", "Chronic Disease"],
          filled=True,
          rounded=True,
          max_depth=3)  # Limiting to first 3 levels for clarity
plt.title("Binary Decision Tree (Depth = 3)")
plt.show()

#random forest classification- binary

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Define parameter grid
param_grid_rf = {
    'n_estimators': [100, 200],               # Number of trees
    'max_depth': [None, 10, 20],              # Tree depth
    'min_samples_split': [2, 5],              # Minimum split size
    'min_samples_leaf': [1, 2],               # Minimum leaf size
    'class_weight': ['balanced']             # Handle class imbalance
}

# Step 2: Initialize model
model3 = RandomForestClassifier(random_state=42)

# Step 3: Grid Search
grid_search_rf = GridSearchCV(estimator=model3, param_grid=param_grid_rf,
                              cv=3, n_jobs=-1, scoring='accuracy')
grid_search_rf.fit(X_train, Y_train)

# Step 4: Best model
best_rf = grid_search_rf.best_estimator_
print("Best Parameters:", grid_search_rf.best_params_)

# Step 5: Predict
pred_rf = best_rf.predict(X_test)
score3=accuracy_score(Y_test, pred_rf)
print("Accuracy:", score3 )
print("Confusion Matrix:\n", confusion_matrix(Y_test, pred_rf))
print("Classification Report:\n", classification_report(Y_test, pred_rf))

# Step 8: Predict on your sample inputs
pred3 = best_rf.predict(sample_df1)[0]
pred3_2 = best_rf.predict(sample_df2)[0]
pred3_3 = best_rf.predict(sample_df3)[0]

# Step 6: Predict on Sample Inputs
print("\nSample Input Predictions:")
print("Sample 1:", "Chronic Disease" if  pred3 == 1 else "No Disease")
print("Sample 2:", "Chronic Disease" if  pred3_2 == 1 else "No Disease")
print("Sample 3:", "Chronic Disease" if  pred3_3 == 1 else "No Disease")

#cannot handle imbalance well and doesn’t allow class weighting, it's not a good fit for our current dataset.


#naive bayes for binary classification
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Define the model
model4 = GaussianNB()

# Step 2: Set hyperparameter grid
param_grid_nb = {
    'var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6]
}

# Step 3: GridSearchCV setup
grid_search_nb = GridSearchCV(model4, param_grid_nb, cv=5, scoring='accuracy')
grid_search_nb.fit(X_train, Y_train)

# Step 4: Best model
best_nb_model = grid_search_nb.best_estimator_
print("Best Parameters:", grid_search_nb.best_params_)

# Step 5: Predict and evaluate
y_pred_nb = best_nb_model.predict(X_test)
score4=accuracy_score(Y_test, y_pred_nb)
print("Accuracy:", score4)
print("Confusion Matrix:\n", confusion_matrix(Y_test, y_pred_nb))
print("Classification Report:\n", classification_report(Y_test, y_pred_nb))

# Step 6: Sample Inputs
pred4 = best_nb_model.predict(sample_df1)[0]
pred4_2 = best_nb_model.predict(sample_df2)[0]
pred4_3 = best_nb_model.predict(sample_df3)[0]

print("\nSample Input Predictions:")
print("Sample 1:", "Chronic Disease" if pred4 == 1 else "No Disease")
print("Sample 2:", "Chronic Disease" if pred4_2 == 1 else "No Disease")
print("Sample 3:", "Chronic Disease" if pred4_3 == 1 else "No Disease")

#SVM FOR BINARY CLASSIFICATION

from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Define model
model5 = SVC(class_weight='balanced', probability=True, random_state=42)

# Step 2: Define hyperparameter grid
param_grid_svm = {
    'C': [0.1, 1, 10],
    'gamma': ['scale', 'auto', 0.1, 1],
    'kernel': ['rbf']
}

# Step 3: Grid search
grid_search_svm = GridSearchCV(model5, param_grid_svm, cv=3, n_jobs=-1, scoring='accuracy')
grid_search_svm.fit(X_train, Y_train)

# Step 4: Best model
best_svm = grid_search_svm.best_estimator_
print("Best Parameters:", grid_search_svm.best_params_)

# Step 5: Predictions & evaluation
y_pred_svm = best_svm.predict(X_test)
score5=accuracy_score(Y_test, y_pred_svm)
print("Accuracy:", score5)
print("Confusion Matrix:\n", confusion_matrix(Y_test, y_pred_svm))
print("Classification Report:\n", classification_report(Y_test, y_pred_svm))

pred5 = best_svm.predict(sample_df1)[0]
pred5_2 = best_svm.predict(sample_df2)[0]
pred5_3 = best_svm.predict(sample_df3)[0]

# Step 6: Sample Input Predictions
print("\nSample Input Predictions:")
print("Sample 1:", "Chronic Disease" if  pred5 == 1 else "No Disease")
print("Sample 2:", "Chronic Disease" if  pred5_2 == 1 else "No Disease")
print("Sample 3:", "Chronic Disease" if  pred5_3 == 1 else "No Disease")

#XGBOOST CLASSIFIER
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score,classification_report,confusion_matrix

# Step 1: Define the model
model6 = XGBClassifier(random_state=42, use_label_encoder=False,
                       eval_metric='logloss')

# Step 2: Define the parameter grid
param_grid_xgb = {
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'scale_pos_weight': [1, 2, 4]  # Handles imbalance }

# Step 3: Run GridSearchCV
grid_search_xgb = GridSearchCV(model6, param_grid_xgb,
                  cv=3, scoring='accuracy', n_jobs=-1)
grid_search_xgb.fit(X_train, Y_train)

# Step 4: Best estimator
best_xgb_model = grid_search_xgb.best_estimator_
print("Best Parameters:", grid_search_xgb.best_params_)

# Step 5: Predict and evaluate
y_pred_xgb = best_xgb_model.predict(X_test)
score6=accuracy_score(Y_test, y_pred_xgb)
print("Accuracy:", score6)
print("Confusion Matrix:\n", confusion_matrix(Y_test, y_pred_xgb))
print("Classification Report:\n", classification_report(Y_test, y_pred_xgb))

pred6 = best_xgb_model.predict(sample_df1)[0]
pred6_2 = best_xgb_model.predict(sample_df2)[0]
pred6_3 = best_xgb_model.predict(sample_df3)[0]

# Step 6: Sample input predictions
print("\nSample Input Predictions:")
print("Sample 1:", "Chronic Disease" if pred6 == 1 else "No Disease")
print("Sample 2:", "Chronic Disease" if pred6_2 == 1 else "No Disease")
print("Sample 3:", "Chronic Disease" if pred6_3 == 1 else "No Disease")

#adaboost classifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# Step 1: Define base model
model7 = AdaBoostClassifier(random_state=42)

# Step 2: Define parameter grid
param_grid_ada = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 1]}

# Step 3: Grid search with 3-fold cross-validation
grid_search_ada = GridSearchCV(model7, param_grid_ada, cv=3,
                               scoring='accuracy', n_jobs=-1)
grid_search_ada.fit(X_train, Y_train)

# Step 4: Best model
best_ada_model = grid_search_ada.best_estimator_
print("Best Parameters:", grid_search_ada.best_params_)

# Step 5: Evaluate on test data
y_pred_ada = best_ada_model.predict(X_test)
score7=accuracy_score(Y_test, y_pred_ada)
print("Accuracy:",score7)
print("Confusion Matrix:\n", confusion_matrix(Y_test, y_pred_ada))
print("Classification Report:\n", classification_report(Y_test, y_pred_ada))

pred7=best_ada_model.predict(sample_df1)[0]
pred7_2=best_ada_model.predict(sample_df2)[0]
pred7_3=best_ada_model.predict(sample_df3)[0]

# Step 6: Predictions on sample inputs
print("\nSample Input Predictions:")
print("Sample 1:", "Chronic Disease" if pred7 == 1 else "No Disease")
print("Sample 2:", "Chronic Disease" if pred7_2 == 1 else "No Disease")
print("Sample 3:", "Chronic Disease" if pred7_3 == 1 else "No Disease")

#Chronic disease prediction(Binary Classification) based on sample_input
a = pd.DataFrame({'Algorithm': ['Logistic Regression(Binary)','Decision Tree','Random Forest Classification','Naive Bayes','SVM','XGBoost','AdaBoost'],
                  'Accuracy': [score1,score2,score3,score4,score5,score6,score7],
                  'Input1': [sample_input,sample_input,sample_input,sample_input,sample_input,sample_input,sample_input],
                  'Actual':[0,0,0,0,0,0,0],
                  'Prediction': [pred1,pred2,pred3,pred4,pred5,pred6,pred7]})
a

#Chronic disease prediction(Binary Classification) based on sample_input2

b = pd.DataFrame({'Algorithm': ['Logistic Regression(Binary)','Decision Tree','Random Forest Classification','Naive Bayes','SVM','XGBoost','AdaBoost'],
                  'Accuracy': [score1,score2,score3,score4,score5,score6,score7],
                  'Input2': [sample_input2,sample_input2,sample_input2,sample_input2,sample_input2,sample_input2,sample_input2],
                  'Actual':[1,1,1,1,1,1,1],
                  'Prediction': [pred1_2,pred2_2,pred3_2,pred4_2,pred5_2,pred6_2,pred7_2]})
b

#Chronic disease prediction(Binary Classification) based on sample_input3

c = pd.DataFrame({'Algorithm': ['Logistic Regression(Binary)','Decision Tree','Random Forest Classification','Naive Bayes','SVM','XGBoost','AdaBoost'],
                  'Accuracy': [score1,score2,score3,score4,score5,score6,score7],
                  'Input3': [sample_input3,sample_input3,sample_input3,sample_input3,sample_input3,sample_input3,sample_input3],
                  'Actual':[0,0,0,0,0,0,0],
                  'Prediction': [pred1_3,pred2_3,pred3_3,pred4_3,pred5_3,pred6_3,pred7_3]})
c

# Labels and corresponding accuracy values (already stored)
algorithms = ['Logistic Regression(Binary)', 'Decision Tree',
              'Random Forest Classification',
              'Naive Bayes', 'SVM', 'XGBoost', 'AdaBoost']
accuracies = [score1, score2, score3, score4, score5, score6, score7]

# Plot the bar chart
plt.figure(figsize=(12, 6))
bars = plt.bar(algorithms, accuracies, color='green')
plt.ylim(0, 1)
plt.title("Model Comparison Based on Accuracy", fontsize=14)
plt.xlabel("Algorithms", fontsize=12)
plt.ylabel("Accuracy", fontsize=12)
plt.xticks(rotation=25)
plt.grid(axis='y', linestyle='--', alpha=0.6)

# Add accuracy labels on top of each bar
for bar in bars:
    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.01,
             f'{bar.get_height():.2f}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.show()

